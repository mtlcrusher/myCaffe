I1129 17:04:39.812294  1629 caffe.cpp:218] Using GPUs 0
I1129 17:04:39.839994  1629 caffe.cpp:223] GPU 0: Tesla P100-PCIE-16GB
I1129 17:04:40.164314  1629 solver.cpp:44] Initializing solver from parameters: 
test_iter: 1000
test_interval: 1000
base_lr: 0.001
display: 50
max_iter: 10000
lr_policy: "fixed"
gamma: 0.1
momentum: 0.9
weight_decay: 0.0005
snapshot: 100
snapshot_prefix: "/content/myCaffe/caffe_models/caffe_model_1/caffe_model_1"
solver_mode: GPU
device_id: 0
net: "/content/myCaffe/caffe_models/caffe_model_1/caffenet_train_val_1.prototxt"
train_state {
  level: 0
  stage: ""
}
momentum2: 0.999
type: "Adam"
I1129 17:04:40.164489  1629 solver.cpp:87] Creating training net from net file: /content/myCaffe/caffe_models/caffe_model_1/caffenet_train_val_1.prototxt
I1129 17:04:40.164813  1629 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer data
I1129 17:04:40.164839  1629 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer accuracy
I1129 17:04:40.164945  1629 net.cpp:51] Initializing net from parameters: 
name: "CaffeNet"
state {
  phase: TRAIN
  level: 0
  stage: ""
}
layer {
  name: "data"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TRAIN
  }
  transform_param {
    mirror: true
    crop_size: 227
    mean_file: "/content/data_dog_cat/mean.binaryproto"
  }
  data_param {
    source: "/content/data_dog_cat/train_lmdb"
    batch_size: 256
    backend: LMDB
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 96
    kernel_size: 11
    stride: 4
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "norm1"
  type: "LRN"
  bottom: "pool1"
  top: "norm1"
  lrn_param {
    local_size: 5
    alpha: 0.0001
    beta: 0.75
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "norm1"
  top: "conv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 2
    kernel_size: 5
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "norm2"
  type: "LRN"
  bottom: "pool2"
  top: "norm2"
  lrn_param {
    local_size: 5
    alpha: 0.0001
    beta: 0.75
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "norm2"
  top: "conv3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "conv3"
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "conv3"
  top: "conv4"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "conv4"
}
layer {
  name: "conv5"
  type: "Convolution"
  bottom: "conv4"
  top: "conv5"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu5"
  type: "ReLU"
  bottom: "conv5"
  top: "conv5"
}
layer {
  name: "pool5"
  type: "Pooling"
  bottom: "conv5"
  top: "pool5"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "fc6"
  type: "InnerProduct"
  bottom: "pool5"
  top: "fc6"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 4096
    weight_filler {
      type: "gaussian"
      std: 0.005
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "fc6"
  top: "fc6"
}
layer {
  name: "drop6"
  type: "Dropout"
  bottom: "fc6"
  top: "fc6"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc7"
  type: "InnerProduct"
  bottom: "fc6"
  top: "fc7"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 4096
    weight_filler {
      type: "gaussian"
      std: 0.005
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu7"
  type: "ReLU"
  bottom: "fc7"
  top: "fc7"
}
layer {
  name: "drop7"
  type: "Dropout"
  bottom: "fc7"
  top: "fc7"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc8"
  type: "InnerProduct"
  bottom: "fc7"
  top: "fc8"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "fc8"
  bottom: "label"
  top: "loss"
}
I1129 17:04:40.165094  1629 layer_factory.hpp:77] Creating layer data
I1129 17:04:40.165190  1629 db_lmdb.cpp:35] Opened lmdb /content/data_dog_cat/train_lmdb
I1129 17:04:40.165228  1629 net.cpp:84] Creating Layer data
I1129 17:04:40.165244  1629 net.cpp:380] data -> data
I1129 17:04:40.165262  1629 net.cpp:380] data -> label
I1129 17:04:40.165277  1629 data_transformer.cpp:25] Loading mean file from: /content/data_dog_cat/mean.binaryproto
I1129 17:04:40.168540  1629 data_layer.cpp:45] output data size: 256,3,227,227
I1129 17:04:40.553869  1629 net.cpp:122] Setting up data
I1129 17:04:40.553982  1629 net.cpp:129] Top shape: 256 3 227 227 (39574272)
I1129 17:04:40.554003  1629 net.cpp:129] Top shape: 256 (256)
I1129 17:04:40.554018  1629 net.cpp:137] Memory required for data: 158298112
I1129 17:04:40.554033  1629 layer_factory.hpp:77] Creating layer conv1
I1129 17:04:40.554060  1629 net.cpp:84] Creating Layer conv1
I1129 17:04:40.554075  1629 net.cpp:406] conv1 <- data
I1129 17:04:40.554095  1629 net.cpp:380] conv1 -> conv1
I1129 17:04:40.567189  1629 net.cpp:122] Setting up conv1
I1129 17:04:40.567271  1629 net.cpp:129] Top shape: 256 96 55 55 (74342400)
I1129 17:04:40.567289  1629 net.cpp:137] Memory required for data: 455667712
I1129 17:04:40.567319  1629 layer_factory.hpp:77] Creating layer relu1
I1129 17:04:40.567343  1629 net.cpp:84] Creating Layer relu1
I1129 17:04:40.567361  1629 net.cpp:406] relu1 <- conv1
I1129 17:04:40.567384  1629 net.cpp:367] relu1 -> conv1 (in-place)
I1129 17:04:40.567414  1629 net.cpp:122] Setting up relu1
I1129 17:04:40.567432  1629 net.cpp:129] Top shape: 256 96 55 55 (74342400)
I1129 17:04:40.567446  1629 net.cpp:137] Memory required for data: 753037312
I1129 17:04:40.567461  1629 layer_factory.hpp:77] Creating layer pool1
I1129 17:04:40.567478  1629 net.cpp:84] Creating Layer pool1
I1129 17:04:40.567492  1629 net.cpp:406] pool1 <- conv1
I1129 17:04:40.567507  1629 net.cpp:380] pool1 -> pool1
I1129 17:04:40.567576  1629 net.cpp:122] Setting up pool1
I1129 17:04:40.567595  1629 net.cpp:129] Top shape: 256 96 27 27 (17915904)
I1129 17:04:40.567608  1629 net.cpp:137] Memory required for data: 824700928
I1129 17:04:40.567637  1629 layer_factory.hpp:77] Creating layer norm1
I1129 17:04:40.567668  1629 net.cpp:84] Creating Layer norm1
I1129 17:04:40.567683  1629 net.cpp:406] norm1 <- pool1
I1129 17:04:40.567706  1629 net.cpp:380] norm1 -> norm1
I1129 17:04:40.567767  1629 net.cpp:122] Setting up norm1
I1129 17:04:40.567787  1629 net.cpp:129] Top shape: 256 96 27 27 (17915904)
I1129 17:04:40.567800  1629 net.cpp:137] Memory required for data: 896364544
I1129 17:04:40.567814  1629 layer_factory.hpp:77] Creating layer conv2
I1129 17:04:40.567834  1629 net.cpp:84] Creating Layer conv2
I1129 17:04:40.567847  1629 net.cpp:406] conv2 <- norm1
I1129 17:04:40.567863  1629 net.cpp:380] conv2 -> conv2
I1129 17:04:40.572396  1629 net.cpp:122] Setting up conv2
I1129 17:04:40.572459  1629 net.cpp:129] Top shape: 256 256 27 27 (47775744)
I1129 17:04:40.572484  1629 net.cpp:137] Memory required for data: 1087467520
I1129 17:04:40.572504  1629 layer_factory.hpp:77] Creating layer relu2
I1129 17:04:40.572523  1629 net.cpp:84] Creating Layer relu2
I1129 17:04:40.572536  1629 net.cpp:406] relu2 <- conv2
I1129 17:04:40.572551  1629 net.cpp:367] relu2 -> conv2 (in-place)
I1129 17:04:40.572566  1629 net.cpp:122] Setting up relu2
I1129 17:04:40.572582  1629 net.cpp:129] Top shape: 256 256 27 27 (47775744)
I1129 17:04:40.572593  1629 net.cpp:137] Memory required for data: 1278570496
I1129 17:04:40.572605  1629 layer_factory.hpp:77] Creating layer pool2
I1129 17:04:40.572620  1629 net.cpp:84] Creating Layer pool2
I1129 17:04:40.572633  1629 net.cpp:406] pool2 <- conv2
I1129 17:04:40.572646  1629 net.cpp:380] pool2 -> pool2
I1129 17:04:40.572698  1629 net.cpp:122] Setting up pool2
I1129 17:04:40.572719  1629 net.cpp:129] Top shape: 256 256 13 13 (11075584)
I1129 17:04:40.572736  1629 net.cpp:137] Memory required for data: 1322872832
I1129 17:04:40.572757  1629 layer_factory.hpp:77] Creating layer norm2
I1129 17:04:40.572772  1629 net.cpp:84] Creating Layer norm2
I1129 17:04:40.572785  1629 net.cpp:406] norm2 <- pool2
I1129 17:04:40.572799  1629 net.cpp:380] norm2 -> norm2
I1129 17:04:40.572839  1629 net.cpp:122] Setting up norm2
I1129 17:04:40.572855  1629 net.cpp:129] Top shape: 256 256 13 13 (11075584)
I1129 17:04:40.572867  1629 net.cpp:137] Memory required for data: 1367175168
I1129 17:04:40.572880  1629 layer_factory.hpp:77] Creating layer conv3
I1129 17:04:40.572896  1629 net.cpp:84] Creating Layer conv3
I1129 17:04:40.572909  1629 net.cpp:406] conv3 <- norm2
I1129 17:04:40.572924  1629 net.cpp:380] conv3 -> conv3
I1129 17:04:40.586139  1629 net.cpp:122] Setting up conv3
I1129 17:04:40.586215  1629 net.cpp:129] Top shape: 256 384 13 13 (16613376)
I1129 17:04:40.586231  1629 net.cpp:137] Memory required for data: 1433628672
I1129 17:04:40.586251  1629 layer_factory.hpp:77] Creating layer relu3
I1129 17:04:40.586267  1629 net.cpp:84] Creating Layer relu3
I1129 17:04:40.586280  1629 net.cpp:406] relu3 <- conv3
I1129 17:04:40.586295  1629 net.cpp:367] relu3 -> conv3 (in-place)
I1129 17:04:40.586311  1629 net.cpp:122] Setting up relu3
I1129 17:04:40.586326  1629 net.cpp:129] Top shape: 256 384 13 13 (16613376)
I1129 17:04:40.586338  1629 net.cpp:137] Memory required for data: 1500082176
I1129 17:04:40.586351  1629 layer_factory.hpp:77] Creating layer conv4
I1129 17:04:40.586369  1629 net.cpp:84] Creating Layer conv4
I1129 17:04:40.586382  1629 net.cpp:406] conv4 <- conv3
I1129 17:04:40.586396  1629 net.cpp:380] conv4 -> conv4
I1129 17:04:40.596426  1629 net.cpp:122] Setting up conv4
I1129 17:04:40.596485  1629 net.cpp:129] Top shape: 256 384 13 13 (16613376)
I1129 17:04:40.596501  1629 net.cpp:137] Memory required for data: 1566535680
I1129 17:04:40.596518  1629 layer_factory.hpp:77] Creating layer relu4
I1129 17:04:40.596534  1629 net.cpp:84] Creating Layer relu4
I1129 17:04:40.596549  1629 net.cpp:406] relu4 <- conv4
I1129 17:04:40.596562  1629 net.cpp:367] relu4 -> conv4 (in-place)
I1129 17:04:40.596578  1629 net.cpp:122] Setting up relu4
I1129 17:04:40.596593  1629 net.cpp:129] Top shape: 256 384 13 13 (16613376)
I1129 17:04:40.596606  1629 net.cpp:137] Memory required for data: 1632989184
I1129 17:04:40.596642  1629 layer_factory.hpp:77] Creating layer conv5
I1129 17:04:40.596662  1629 net.cpp:84] Creating Layer conv5
I1129 17:04:40.596674  1629 net.cpp:406] conv5 <- conv4
I1129 17:04:40.596699  1629 net.cpp:380] conv5 -> conv5
I1129 17:04:40.606171  1629 net.cpp:122] Setting up conv5
I1129 17:04:40.606250  1629 net.cpp:129] Top shape: 256 256 13 13 (11075584)
I1129 17:04:40.606271  1629 net.cpp:137] Memory required for data: 1677291520
I1129 17:04:40.606293  1629 layer_factory.hpp:77] Creating layer relu5
I1129 17:04:40.606317  1629 net.cpp:84] Creating Layer relu5
I1129 17:04:40.606333  1629 net.cpp:406] relu5 <- conv5
I1129 17:04:40.606350  1629 net.cpp:367] relu5 -> conv5 (in-place)
I1129 17:04:40.606369  1629 net.cpp:122] Setting up relu5
I1129 17:04:40.606386  1629 net.cpp:129] Top shape: 256 256 13 13 (11075584)
I1129 17:04:40.606401  1629 net.cpp:137] Memory required for data: 1721593856
I1129 17:04:40.606416  1629 layer_factory.hpp:77] Creating layer pool5
I1129 17:04:40.606448  1629 net.cpp:84] Creating Layer pool5
I1129 17:04:40.606464  1629 net.cpp:406] pool5 <- conv5
I1129 17:04:40.606480  1629 net.cpp:380] pool5 -> pool5
I1129 17:04:40.606540  1629 net.cpp:122] Setting up pool5
I1129 17:04:40.606561  1629 net.cpp:129] Top shape: 256 256 6 6 (2359296)
I1129 17:04:40.606575  1629 net.cpp:137] Memory required for data: 1731031040
I1129 17:04:40.606593  1629 layer_factory.hpp:77] Creating layer fc6
I1129 17:04:40.606622  1629 net.cpp:84] Creating Layer fc6
I1129 17:04:40.606642  1629 net.cpp:406] fc6 <- pool5
I1129 17:04:40.606660  1629 net.cpp:380] fc6 -> fc6
I1129 17:04:41.112936  1629 net.cpp:122] Setting up fc6
I1129 17:04:41.113080  1629 net.cpp:129] Top shape: 256 4096 (1048576)
I1129 17:04:41.113101  1629 net.cpp:137] Memory required for data: 1735225344
I1129 17:04:41.113121  1629 layer_factory.hpp:77] Creating layer relu6
I1129 17:04:41.113144  1629 net.cpp:84] Creating Layer relu6
I1129 17:04:41.113174  1629 net.cpp:406] relu6 <- fc6
I1129 17:04:41.113194  1629 net.cpp:367] relu6 -> fc6 (in-place)
I1129 17:04:41.113216  1629 net.cpp:122] Setting up relu6
I1129 17:04:41.113232  1629 net.cpp:129] Top shape: 256 4096 (1048576)
I1129 17:04:41.113243  1629 net.cpp:137] Memory required for data: 1739419648
I1129 17:04:41.113255  1629 layer_factory.hpp:77] Creating layer drop6
I1129 17:04:41.113273  1629 net.cpp:84] Creating Layer drop6
I1129 17:04:41.113287  1629 net.cpp:406] drop6 <- fc6
I1129 17:04:41.113302  1629 net.cpp:367] drop6 -> fc6 (in-place)
I1129 17:04:41.113339  1629 net.cpp:122] Setting up drop6
I1129 17:04:41.113356  1629 net.cpp:129] Top shape: 256 4096 (1048576)
I1129 17:04:41.113370  1629 net.cpp:137] Memory required for data: 1743613952
I1129 17:04:41.113384  1629 layer_factory.hpp:77] Creating layer fc7
I1129 17:04:41.113404  1629 net.cpp:84] Creating Layer fc7
I1129 17:04:41.113422  1629 net.cpp:406] fc7 <- fc6
I1129 17:04:41.113438  1629 net.cpp:380] fc7 -> fc7
I1129 17:04:41.277669  1629 net.cpp:122] Setting up fc7
I1129 17:04:41.277729  1629 net.cpp:129] Top shape: 256 4096 (1048576)
I1129 17:04:41.277734  1629 net.cpp:137] Memory required for data: 1747808256
I1129 17:04:41.277743  1629 layer_factory.hpp:77] Creating layer relu7
I1129 17:04:41.277755  1629 net.cpp:84] Creating Layer relu7
I1129 17:04:41.277760  1629 net.cpp:406] relu7 <- fc7
I1129 17:04:41.277766  1629 net.cpp:367] relu7 -> fc7 (in-place)
I1129 17:04:41.277776  1629 net.cpp:122] Setting up relu7
I1129 17:04:41.277779  1629 net.cpp:129] Top shape: 256 4096 (1048576)
I1129 17:04:41.277783  1629 net.cpp:137] Memory required for data: 1752002560
I1129 17:04:41.277786  1629 layer_factory.hpp:77] Creating layer drop7
I1129 17:04:41.277793  1629 net.cpp:84] Creating Layer drop7
I1129 17:04:41.277796  1629 net.cpp:406] drop7 <- fc7
I1129 17:04:41.277801  1629 net.cpp:367] drop7 -> fc7 (in-place)
I1129 17:04:41.277817  1629 net.cpp:122] Setting up drop7
I1129 17:04:41.277848  1629 net.cpp:129] Top shape: 256 4096 (1048576)
I1129 17:04:41.277851  1629 net.cpp:137] Memory required for data: 1756196864
I1129 17:04:41.277855  1629 layer_factory.hpp:77] Creating layer fc8
I1129 17:04:41.277889  1629 net.cpp:84] Creating Layer fc8
I1129 17:04:41.277896  1629 net.cpp:406] fc8 <- fc7
I1129 17:04:41.277902  1629 net.cpp:380] fc8 -> fc8
I1129 17:04:41.278048  1629 net.cpp:122] Setting up fc8
I1129 17:04:41.278059  1629 net.cpp:129] Top shape: 256 2 (512)
I1129 17:04:41.278064  1629 net.cpp:137] Memory required for data: 1756198912
I1129 17:04:41.278069  1629 layer_factory.hpp:77] Creating layer loss
I1129 17:04:41.278076  1629 net.cpp:84] Creating Layer loss
I1129 17:04:41.278080  1629 net.cpp:406] loss <- fc8
I1129 17:04:41.278084  1629 net.cpp:406] loss <- label
I1129 17:04:41.278090  1629 net.cpp:380] loss -> loss
I1129 17:04:41.278098  1629 layer_factory.hpp:77] Creating layer loss
I1129 17:04:41.278175  1629 net.cpp:122] Setting up loss
I1129 17:04:41.278185  1629 net.cpp:129] Top shape: (1)
I1129 17:04:41.278188  1629 net.cpp:132]     with loss weight 1
I1129 17:04:41.278221  1629 net.cpp:137] Memory required for data: 1756198916
I1129 17:04:41.278226  1629 net.cpp:198] loss needs backward computation.
I1129 17:04:41.278234  1629 net.cpp:198] fc8 needs backward computation.
I1129 17:04:41.278237  1629 net.cpp:198] drop7 needs backward computation.
I1129 17:04:41.278242  1629 net.cpp:198] relu7 needs backward computation.
I1129 17:04:41.278245  1629 net.cpp:198] fc7 needs backward computation.
I1129 17:04:41.278250  1629 net.cpp:198] drop6 needs backward computation.
I1129 17:04:41.278254  1629 net.cpp:198] relu6 needs backward computation.
I1129 17:04:41.278275  1629 net.cpp:198] fc6 needs backward computation.
I1129 17:04:41.278280  1629 net.cpp:198] pool5 needs backward computation.
I1129 17:04:41.278285  1629 net.cpp:198] relu5 needs backward computation.
I1129 17:04:41.278288  1629 net.cpp:198] conv5 needs backward computation.
I1129 17:04:41.278293  1629 net.cpp:198] relu4 needs backward computation.
I1129 17:04:41.278297  1629 net.cpp:198] conv4 needs backward computation.
I1129 17:04:41.278301  1629 net.cpp:198] relu3 needs backward computation.
I1129 17:04:41.278306  1629 net.cpp:198] conv3 needs backward computation.
I1129 17:04:41.278311  1629 net.cpp:198] norm2 needs backward computation.
I1129 17:04:41.278316  1629 net.cpp:198] pool2 needs backward computation.
I1129 17:04:41.278319  1629 net.cpp:198] relu2 needs backward computation.
I1129 17:04:41.278323  1629 net.cpp:198] conv2 needs backward computation.
I1129 17:04:41.278328  1629 net.cpp:198] norm1 needs backward computation.
I1129 17:04:41.278332  1629 net.cpp:198] pool1 needs backward computation.
I1129 17:04:41.278337  1629 net.cpp:198] relu1 needs backward computation.
I1129 17:04:41.278342  1629 net.cpp:198] conv1 needs backward computation.
I1129 17:04:41.278347  1629 net.cpp:200] data does not need backward computation.
I1129 17:04:41.278352  1629 net.cpp:242] This network produces output loss
I1129 17:04:41.278364  1629 net.cpp:255] Network initialization done.
I1129 17:04:41.278671  1629 solver.cpp:172] Creating test net (#0) specified by net file: /content/myCaffe/caffe_models/caffe_model_1/caffenet_train_val_1.prototxt
I1129 17:04:41.278725  1629 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer data
I1129 17:04:41.278867  1629 net.cpp:51] Initializing net from parameters: 
name: "CaffeNet"
state {
  phase: TEST
}
layer {
  name: "data"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TEST
  }
  transform_param {
    mirror: false
    crop_size: 227
    mean_file: "/content/data_dog_cat/mean.binaryproto"
  }
  data_param {
    source: "/content/data_dog_cat/validation_lmdb"
    batch_size: 50
    backend: LMDB
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 96
    kernel_size: 11
    stride: 4
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "norm1"
  type: "LRN"
  bottom: "pool1"
  top: "norm1"
  lrn_param {
    local_size: 5
    alpha: 0.0001
    beta: 0.75
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "norm1"
  top: "conv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 2
    kernel_size: 5
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "norm2"
  type: "LRN"
  bottom: "pool2"
  top: "norm2"
  lrn_param {
    local_size: 5
    alpha: 0.0001
    beta: 0.75
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "norm2"
  top: "conv3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "conv3"
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "conv3"
  top: "conv4"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "conv4"
}
layer {
  name: "conv5"
  type: "Convolution"
  bottom: "conv4"
  top: "conv5"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu5"
  type: "ReLU"
  bottom: "conv5"
  top: "conv5"
}
layer {
  name: "pool5"
  type: "Pooling"
  bottom: "conv5"
  top: "pool5"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "fc6"
  type: "InnerProduct"
  bottom: "pool5"
  top: "fc6"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 4096
    weight_filler {
      type: "gaussian"
      std: 0.005
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "fc6"
  top: "fc6"
}
layer {
  name: "drop6"
  type: "Dropout"
  bottom: "fc6"
  top: "fc6"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc7"
  type: "InnerProduct"
  bottom: "fc6"
  top: "fc7"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 4096
    weight_filler {
      type: "gaussian"
      std: 0.005
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu7"
  type: "ReLU"
  bottom: "fc7"
  top: "fc7"
}
layer {
  name: "drop7"
  type: "Dropout"
  bottom: "fc7"
  top: "fc7"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc8"
  type: "InnerProduct"
  bottom: "fc7"
  top: "fc8"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "accuracy"
  type: "Accuracy"
  bottom: "fc8"
  bottom: "label"
  top: "accuracy"
  include {
    phase: TEST
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "fc8"
  bottom: "label"
  top: "loss"
}
I1129 17:04:41.278978  1629 layer_factory.hpp:77] Creating layer data
I1129 17:04:41.279067  1629 db_lmdb.cpp:35] Opened lmdb /content/data_dog_cat/validation_lmdb
I1129 17:04:41.279088  1629 net.cpp:84] Creating Layer data
I1129 17:04:41.279096  1629 net.cpp:380] data -> data
I1129 17:04:41.279105  1629 net.cpp:380] data -> label
I1129 17:04:41.279114  1629 data_transformer.cpp:25] Loading mean file from: /content/data_dog_cat/mean.binaryproto
I1129 17:04:41.281889  1629 data_layer.cpp:45] output data size: 50,3,227,227
I1129 17:04:41.360792  1629 net.cpp:122] Setting up data
I1129 17:04:41.360898  1629 net.cpp:129] Top shape: 50 3 227 227 (7729350)
I1129 17:04:41.360918  1629 net.cpp:129] Top shape: 50 (50)
I1129 17:04:41.360934  1629 net.cpp:137] Memory required for data: 30917600
I1129 17:04:41.360949  1629 layer_factory.hpp:77] Creating layer label_data_1_split
I1129 17:04:41.360975  1629 net.cpp:84] Creating Layer label_data_1_split
I1129 17:04:41.360990  1629 net.cpp:406] label_data_1_split <- label
I1129 17:04:41.361007  1629 net.cpp:380] label_data_1_split -> label_data_1_split_0
I1129 17:04:41.361028  1629 net.cpp:380] label_data_1_split -> label_data_1_split_1
I1129 17:04:41.361088  1629 net.cpp:122] Setting up label_data_1_split
I1129 17:04:41.361104  1629 net.cpp:129] Top shape: 50 (50)
I1129 17:04:41.361119  1629 net.cpp:129] Top shape: 50 (50)
I1129 17:04:41.361132  1629 net.cpp:137] Memory required for data: 30918000
I1129 17:04:41.361145  1629 layer_factory.hpp:77] Creating layer conv1
I1129 17:04:41.361182  1629 net.cpp:84] Creating Layer conv1
I1129 17:04:41.361202  1629 net.cpp:406] conv1 <- data
I1129 17:04:41.361219  1629 net.cpp:380] conv1 -> conv1
I1129 17:04:41.364135  1629 net.cpp:122] Setting up conv1
I1129 17:04:41.364239  1629 net.cpp:129] Top shape: 50 96 55 55 (14520000)
I1129 17:04:41.364259  1629 net.cpp:137] Memory required for data: 88998000
I1129 17:04:41.364285  1629 layer_factory.hpp:77] Creating layer relu1
I1129 17:04:41.364308  1629 net.cpp:84] Creating Layer relu1
I1129 17:04:41.364327  1629 net.cpp:406] relu1 <- conv1
I1129 17:04:41.364344  1629 net.cpp:367] relu1 -> conv1 (in-place)
I1129 17:04:41.364362  1629 net.cpp:122] Setting up relu1
I1129 17:04:41.364377  1629 net.cpp:129] Top shape: 50 96 55 55 (14520000)
I1129 17:04:41.364389  1629 net.cpp:137] Memory required for data: 147078000
I1129 17:04:41.364403  1629 layer_factory.hpp:77] Creating layer pool1
I1129 17:04:41.364419  1629 net.cpp:84] Creating Layer pool1
I1129 17:04:41.364432  1629 net.cpp:406] pool1 <- conv1
I1129 17:04:41.364447  1629 net.cpp:380] pool1 -> pool1
I1129 17:04:41.364507  1629 net.cpp:122] Setting up pool1
I1129 17:04:41.364537  1629 net.cpp:129] Top shape: 50 96 27 27 (3499200)
I1129 17:04:41.364550  1629 net.cpp:137] Memory required for data: 161074800
I1129 17:04:41.364564  1629 layer_factory.hpp:77] Creating layer norm1
I1129 17:04:41.364588  1629 net.cpp:84] Creating Layer norm1
I1129 17:04:41.364604  1629 net.cpp:406] norm1 <- pool1
I1129 17:04:41.364624  1629 net.cpp:380] norm1 -> norm1
I1129 17:04:41.364671  1629 net.cpp:122] Setting up norm1
I1129 17:04:41.364687  1629 net.cpp:129] Top shape: 50 96 27 27 (3499200)
I1129 17:04:41.364701  1629 net.cpp:137] Memory required for data: 175071600
I1129 17:04:41.364712  1629 layer_factory.hpp:77] Creating layer conv2
I1129 17:04:41.364735  1629 net.cpp:84] Creating Layer conv2
I1129 17:04:41.364749  1629 net.cpp:406] conv2 <- norm1
I1129 17:04:41.364763  1629 net.cpp:380] conv2 -> conv2
I1129 17:04:41.369335  1629 net.cpp:122] Setting up conv2
I1129 17:04:41.369385  1629 net.cpp:129] Top shape: 50 256 27 27 (9331200)
I1129 17:04:41.369406  1629 net.cpp:137] Memory required for data: 212396400
I1129 17:04:41.369452  1629 layer_factory.hpp:77] Creating layer relu2
I1129 17:04:41.369472  1629 net.cpp:84] Creating Layer relu2
I1129 17:04:41.369498  1629 net.cpp:406] relu2 <- conv2
I1129 17:04:41.369545  1629 net.cpp:367] relu2 -> conv2 (in-place)
I1129 17:04:41.369561  1629 net.cpp:122] Setting up relu2
I1129 17:04:41.369575  1629 net.cpp:129] Top shape: 50 256 27 27 (9331200)
I1129 17:04:41.369588  1629 net.cpp:137] Memory required for data: 249721200
I1129 17:04:41.369601  1629 layer_factory.hpp:77] Creating layer pool2
I1129 17:04:41.369617  1629 net.cpp:84] Creating Layer pool2
I1129 17:04:41.369630  1629 net.cpp:406] pool2 <- conv2
I1129 17:04:41.369644  1629 net.cpp:380] pool2 -> pool2
I1129 17:04:41.369699  1629 net.cpp:122] Setting up pool2
I1129 17:04:41.369724  1629 net.cpp:129] Top shape: 50 256 13 13 (2163200)
I1129 17:04:41.369742  1629 net.cpp:137] Memory required for data: 258374000
I1129 17:04:41.369755  1629 layer_factory.hpp:77] Creating layer norm2
I1129 17:04:41.369772  1629 net.cpp:84] Creating Layer norm2
I1129 17:04:41.369784  1629 net.cpp:406] norm2 <- pool2
I1129 17:04:41.369798  1629 net.cpp:380] norm2 -> norm2
I1129 17:04:41.369846  1629 net.cpp:122] Setting up norm2
I1129 17:04:41.369863  1629 net.cpp:129] Top shape: 50 256 13 13 (2163200)
I1129 17:04:41.369874  1629 net.cpp:137] Memory required for data: 267026800
I1129 17:04:41.369887  1629 layer_factory.hpp:77] Creating layer conv3
I1129 17:04:41.369905  1629 net.cpp:84] Creating Layer conv3
I1129 17:04:41.369917  1629 net.cpp:406] conv3 <- norm2
I1129 17:04:41.369932  1629 net.cpp:380] conv3 -> conv3
I1129 17:04:41.392982  1629 net.cpp:122] Setting up conv3
I1129 17:04:41.393051  1629 net.cpp:129] Top shape: 50 384 13 13 (3244800)
I1129 17:04:41.393072  1629 net.cpp:137] Memory required for data: 280006000
I1129 17:04:41.393100  1629 layer_factory.hpp:77] Creating layer relu3
I1129 17:04:41.393128  1629 net.cpp:84] Creating Layer relu3
I1129 17:04:41.393143  1629 net.cpp:406] relu3 <- conv3
I1129 17:04:41.393178  1629 net.cpp:367] relu3 -> conv3 (in-place)
I1129 17:04:41.393200  1629 net.cpp:122] Setting up relu3
I1129 17:04:41.393216  1629 net.cpp:129] Top shape: 50 384 13 13 (3244800)
I1129 17:04:41.393229  1629 net.cpp:137] Memory required for data: 292985200
I1129 17:04:41.393244  1629 layer_factory.hpp:77] Creating layer conv4
I1129 17:04:41.393262  1629 net.cpp:84] Creating Layer conv4
I1129 17:04:41.393276  1629 net.cpp:406] conv4 <- conv3
I1129 17:04:41.393291  1629 net.cpp:380] conv4 -> conv4
I1129 17:04:41.405753  1629 net.cpp:122] Setting up conv4
I1129 17:04:41.405822  1629 net.cpp:129] Top shape: 50 384 13 13 (3244800)
I1129 17:04:41.405839  1629 net.cpp:137] Memory required for data: 305964400
I1129 17:04:41.405858  1629 layer_factory.hpp:77] Creating layer relu4
I1129 17:04:41.405884  1629 net.cpp:84] Creating Layer relu4
I1129 17:04:41.405901  1629 net.cpp:406] relu4 <- conv4
I1129 17:04:41.405925  1629 net.cpp:367] relu4 -> conv4 (in-place)
I1129 17:04:41.405942  1629 net.cpp:122] Setting up relu4
I1129 17:04:41.405958  1629 net.cpp:129] Top shape: 50 384 13 13 (3244800)
I1129 17:04:41.405972  1629 net.cpp:137] Memory required for data: 318943600
I1129 17:04:41.405985  1629 layer_factory.hpp:77] Creating layer conv5
I1129 17:04:41.406009  1629 net.cpp:84] Creating Layer conv5
I1129 17:04:41.406023  1629 net.cpp:406] conv5 <- conv4
I1129 17:04:41.406038  1629 net.cpp:380] conv5 -> conv5
I1129 17:04:41.413305  1629 net.cpp:122] Setting up conv5
I1129 17:04:41.413364  1629 net.cpp:129] Top shape: 50 256 13 13 (2163200)
I1129 17:04:41.413380  1629 net.cpp:137] Memory required for data: 327596400
I1129 17:04:41.413401  1629 layer_factory.hpp:77] Creating layer relu5
I1129 17:04:41.413420  1629 net.cpp:84] Creating Layer relu5
I1129 17:04:41.413439  1629 net.cpp:406] relu5 <- conv5
I1129 17:04:41.413465  1629 net.cpp:367] relu5 -> conv5 (in-place)
I1129 17:04:41.413483  1629 net.cpp:122] Setting up relu5
I1129 17:04:41.413499  1629 net.cpp:129] Top shape: 50 256 13 13 (2163200)
I1129 17:04:41.413512  1629 net.cpp:137] Memory required for data: 336249200
I1129 17:04:41.413527  1629 layer_factory.hpp:77] Creating layer pool5
I1129 17:04:41.413552  1629 net.cpp:84] Creating Layer pool5
I1129 17:04:41.413578  1629 net.cpp:406] pool5 <- conv5
I1129 17:04:41.413605  1629 net.cpp:380] pool5 -> pool5
I1129 17:04:41.413678  1629 net.cpp:122] Setting up pool5
I1129 17:04:41.413712  1629 net.cpp:129] Top shape: 50 256 6 6 (460800)
I1129 17:04:41.413727  1629 net.cpp:137] Memory required for data: 338092400
I1129 17:04:41.413739  1629 layer_factory.hpp:77] Creating layer fc6
I1129 17:04:41.413763  1629 net.cpp:84] Creating Layer fc6
I1129 17:04:41.413780  1629 net.cpp:406] fc6 <- pool5
I1129 17:04:41.413800  1629 net.cpp:380] fc6 -> fc6
I1129 17:04:41.783404  1629 net.cpp:122] Setting up fc6
I1129 17:04:41.783445  1629 net.cpp:129] Top shape: 50 4096 (204800)
I1129 17:04:41.783450  1629 net.cpp:137] Memory required for data: 338911600
I1129 17:04:41.783460  1629 layer_factory.hpp:77] Creating layer relu6
I1129 17:04:41.783473  1629 net.cpp:84] Creating Layer relu6
I1129 17:04:41.783478  1629 net.cpp:406] relu6 <- fc6
I1129 17:04:41.783486  1629 net.cpp:367] relu6 -> fc6 (in-place)
I1129 17:04:41.783495  1629 net.cpp:122] Setting up relu6
I1129 17:04:41.783500  1629 net.cpp:129] Top shape: 50 4096 (204800)
I1129 17:04:41.783504  1629 net.cpp:137] Memory required for data: 339730800
I1129 17:04:41.783507  1629 layer_factory.hpp:77] Creating layer drop6
I1129 17:04:41.783514  1629 net.cpp:84] Creating Layer drop6
I1129 17:04:41.783519  1629 net.cpp:406] drop6 <- fc6
I1129 17:04:41.783522  1629 net.cpp:367] drop6 -> fc6 (in-place)
I1129 17:04:41.783551  1629 net.cpp:122] Setting up drop6
I1129 17:04:41.783562  1629 net.cpp:129] Top shape: 50 4096 (204800)
I1129 17:04:41.783565  1629 net.cpp:137] Memory required for data: 340550000
I1129 17:04:41.783569  1629 layer_factory.hpp:77] Creating layer fc7
I1129 17:04:41.783577  1629 net.cpp:84] Creating Layer fc7
I1129 17:04:41.783586  1629 net.cpp:406] fc7 <- fc6
I1129 17:04:41.783592  1629 net.cpp:380] fc7 -> fc7
I1129 17:04:41.942682  1629 net.cpp:122] Setting up fc7
I1129 17:04:41.942735  1629 net.cpp:129] Top shape: 50 4096 (204800)
I1129 17:04:41.942740  1629 net.cpp:137] Memory required for data: 341369200
I1129 17:04:41.942750  1629 layer_factory.hpp:77] Creating layer relu7
I1129 17:04:41.942761  1629 net.cpp:84] Creating Layer relu7
I1129 17:04:41.942766  1629 net.cpp:406] relu7 <- fc7
I1129 17:04:41.942775  1629 net.cpp:367] relu7 -> fc7 (in-place)
I1129 17:04:41.942782  1629 net.cpp:122] Setting up relu7
I1129 17:04:41.942786  1629 net.cpp:129] Top shape: 50 4096 (204800)
I1129 17:04:41.942790  1629 net.cpp:137] Memory required for data: 342188400
I1129 17:04:41.942793  1629 layer_factory.hpp:77] Creating layer drop7
I1129 17:04:41.942798  1629 net.cpp:84] Creating Layer drop7
I1129 17:04:41.942802  1629 net.cpp:406] drop7 <- fc7
I1129 17:04:41.942806  1629 net.cpp:367] drop7 -> fc7 (in-place)
I1129 17:04:41.942834  1629 net.cpp:122] Setting up drop7
I1129 17:04:41.942843  1629 net.cpp:129] Top shape: 50 4096 (204800)
I1129 17:04:41.942847  1629 net.cpp:137] Memory required for data: 343007600
I1129 17:04:41.942852  1629 layer_factory.hpp:77] Creating layer fc8
I1129 17:04:41.942860  1629 net.cpp:84] Creating Layer fc8
I1129 17:04:41.942867  1629 net.cpp:406] fc8 <- fc7
I1129 17:04:41.942873  1629 net.cpp:380] fc8 -> fc8
I1129 17:04:41.943017  1629 net.cpp:122] Setting up fc8
I1129 17:04:41.943027  1629 net.cpp:129] Top shape: 50 2 (100)
I1129 17:04:41.943030  1629 net.cpp:137] Memory required for data: 343008000
I1129 17:04:41.943037  1629 layer_factory.hpp:77] Creating layer fc8_fc8_0_split
I1129 17:04:41.943042  1629 net.cpp:84] Creating Layer fc8_fc8_0_split
I1129 17:04:41.943047  1629 net.cpp:406] fc8_fc8_0_split <- fc8
I1129 17:04:41.943051  1629 net.cpp:380] fc8_fc8_0_split -> fc8_fc8_0_split_0
I1129 17:04:41.943058  1629 net.cpp:380] fc8_fc8_0_split -> fc8_fc8_0_split_1
I1129 17:04:41.943089  1629 net.cpp:122] Setting up fc8_fc8_0_split
I1129 17:04:41.943099  1629 net.cpp:129] Top shape: 50 2 (100)
I1129 17:04:41.943104  1629 net.cpp:129] Top shape: 50 2 (100)
I1129 17:04:41.943107  1629 net.cpp:137] Memory required for data: 343008800
I1129 17:04:41.943111  1629 layer_factory.hpp:77] Creating layer accuracy
I1129 17:04:41.943147  1629 net.cpp:84] Creating Layer accuracy
I1129 17:04:41.943152  1629 net.cpp:406] accuracy <- fc8_fc8_0_split_0
I1129 17:04:41.943167  1629 net.cpp:406] accuracy <- label_data_1_split_0
I1129 17:04:41.943173  1629 net.cpp:380] accuracy -> accuracy
I1129 17:04:41.943182  1629 net.cpp:122] Setting up accuracy
I1129 17:04:41.943186  1629 net.cpp:129] Top shape: (1)
I1129 17:04:41.943190  1629 net.cpp:137] Memory required for data: 343008804
I1129 17:04:41.943194  1629 layer_factory.hpp:77] Creating layer loss
I1129 17:04:41.943202  1629 net.cpp:84] Creating Layer loss
I1129 17:04:41.943205  1629 net.cpp:406] loss <- fc8_fc8_0_split_1
I1129 17:04:41.943210  1629 net.cpp:406] loss <- label_data_1_split_1
I1129 17:04:41.943219  1629 net.cpp:380] loss -> loss
I1129 17:04:41.943228  1629 layer_factory.hpp:77] Creating layer loss
I1129 17:04:41.943312  1629 net.cpp:122] Setting up loss
I1129 17:04:41.943322  1629 net.cpp:129] Top shape: (1)
I1129 17:04:41.943325  1629 net.cpp:132]     with loss weight 1
I1129 17:04:41.943342  1629 net.cpp:137] Memory required for data: 343008808
I1129 17:04:41.943347  1629 net.cpp:198] loss needs backward computation.
I1129 17:04:41.943352  1629 net.cpp:200] accuracy does not need backward computation.
I1129 17:04:41.943357  1629 net.cpp:198] fc8_fc8_0_split needs backward computation.
I1129 17:04:41.943361  1629 net.cpp:198] fc8 needs backward computation.
I1129 17:04:41.943365  1629 net.cpp:198] drop7 needs backward computation.
I1129 17:04:41.943369  1629 net.cpp:198] relu7 needs backward computation.
I1129 17:04:41.943373  1629 net.cpp:198] fc7 needs backward computation.
I1129 17:04:41.943377  1629 net.cpp:198] drop6 needs backward computation.
I1129 17:04:41.943382  1629 net.cpp:198] relu6 needs backward computation.
I1129 17:04:41.943385  1629 net.cpp:198] fc6 needs backward computation.
I1129 17:04:41.943389  1629 net.cpp:198] pool5 needs backward computation.
I1129 17:04:41.943394  1629 net.cpp:198] relu5 needs backward computation.
I1129 17:04:41.943398  1629 net.cpp:198] conv5 needs backward computation.
I1129 17:04:41.943403  1629 net.cpp:198] relu4 needs backward computation.
I1129 17:04:41.943406  1629 net.cpp:198] conv4 needs backward computation.
I1129 17:04:41.943410  1629 net.cpp:198] relu3 needs backward computation.
I1129 17:04:41.943414  1629 net.cpp:198] conv3 needs backward computation.
I1129 17:04:41.943419  1629 net.cpp:198] norm2 needs backward computation.
I1129 17:04:41.943423  1629 net.cpp:198] pool2 needs backward computation.
I1129 17:04:41.943428  1629 net.cpp:198] relu2 needs backward computation.
I1129 17:04:41.943431  1629 net.cpp:198] conv2 needs backward computation.
I1129 17:04:41.943436  1629 net.cpp:198] norm1 needs backward computation.
I1129 17:04:41.943440  1629 net.cpp:198] pool1 needs backward computation.
I1129 17:04:41.943444  1629 net.cpp:198] relu1 needs backward computation.
I1129 17:04:41.943449  1629 net.cpp:198] conv1 needs backward computation.
I1129 17:04:41.943454  1629 net.cpp:200] label_data_1_split does not need backward computation.
I1129 17:04:41.943457  1629 net.cpp:200] data does not need backward computation.
I1129 17:04:41.943461  1629 net.cpp:242] This network produces output accuracy
I1129 17:04:41.943465  1629 net.cpp:242] This network produces output loss
I1129 17:04:41.943483  1629 net.cpp:255] Network initialization done.
I1129 17:04:41.943562  1629 solver.cpp:56] Solver scaffolding done.
I1129 17:04:41.944083  1629 caffe.cpp:248] Starting Optimization
I1129 17:04:41.944094  1629 solver.cpp:272] Solving CaffeNet
I1129 17:04:41.944098  1629 solver.cpp:273] Learning Rate Policy: fixed
I1129 17:04:41.945116  1629 solver.cpp:330] Iteration 0, Testing net (#0)
I1129 17:04:44.528954  1638 data_layer.cpp:73] Restarting data prefetching from start.
I1129 17:04:47.149926  1638 data_layer.cpp:73] Restarting data prefetching from start.
I1129 17:04:49.781177  1638 data_layer.cpp:73] Restarting data prefetching from start.
I1129 17:04:52.395153  1638 data_layer.cpp:73] Restarting data prefetching from start.
I1129 17:04:55.016122  1638 data_layer.cpp:73] Restarting data prefetching from start.
I1129 17:04:57.638466  1638 data_layer.cpp:73] Restarting data prefetching from start.
I1129 17:05:00.263561  1638 data_layer.cpp:73] Restarting data prefetching from start.
I1129 17:05:02.884357  1638 data_layer.cpp:73] Restarting data prefetching from start.
I1129 17:05:05.504070  1638 data_layer.cpp:73] Restarting data prefetching from start.
I1129 17:05:08.116039  1638 data_layer.cpp:73] Restarting data prefetching from start.
I1129 17:05:10.730233  1638 data_layer.cpp:73] Restarting data prefetching from start.
I1129 17:05:13.374372  1638 data_layer.cpp:73] Restarting data prefetching from start.
I1129 17:05:13.459398  1629 solver.cpp:397]     Test net output #0: accuracy = 0
I1129 17:05:13.459519  1629 solver.cpp:397]     Test net output #1: loss = 0.957168 (* 1 = 0.957168 loss)
I1129 17:05:13.876641  1629 solver.cpp:218] Iteration 0 (0 iter/s, 31.9162s/50 iters), loss = 1.06994
I1129 17:05:13.876724  1629 solver.cpp:237]     Train net output #0: loss = 1.06994 (* 1 = 1.06994 loss)
I1129 17:05:13.876732  1629 sgd_solver.cpp:105] Iteration 0, lr = 0.001
I1129 17:05:35.227795  1629 solver.cpp:218] Iteration 50 (2.34288 iter/s, 21.3412s/50 iters), loss = 0
I1129 17:05:35.227926  1629 solver.cpp:237]     Train net output #0: loss = 0 (* 1 = 0 loss)
I1129 17:05:35.227949  1629 sgd_solver.cpp:105] Iteration 50, lr = 0.001
I1129 17:05:46.817468  1637 data_layer.cpp:73] Restarting data prefetching from start.
I1129 17:05:56.092743  1629 solver.cpp:447] Snapshotting to binary proto file /content/myCaffe/caffe_models/caffe_model_1/caffe_model_1_iter_100.caffemodel
I1129 17:05:58.246428  1629 sgd_solver.cpp:273] Snapshotting solver state to binary proto file /content/myCaffe/caffe_models/caffe_model_1/caffe_model_1_iter_100.solverstate
I1129 17:05:59.761003  1629 solver.cpp:218] Iteration 100 (2.03892 iter/s, 24.5227s/50 iters), loss = 0
I1129 17:05:59.761198  1629 solver.cpp:237]     Train net output #0: loss = 0 (* 1 = 0 loss)
I1129 17:05:59.761235  1629 sgd_solver.cpp:105] Iteration 100, lr = 0.001
I1129 17:06:21.117832  1629 solver.cpp:218] Iteration 150 (2.3421 iter/s, 21.3484s/50 iters), loss = 0
I1129 17:06:21.118074  1629 solver.cpp:237]     Train net output #0: loss = 0 (* 1 = 0 loss)
I1129 17:06:21.118100  1629 sgd_solver.cpp:105] Iteration 150, lr = 0.001
I1129 17:06:24.622702  1637 data_layer.cpp:73] Restarting data prefetching from start.
I1129 17:06:41.995213  1629 solver.cpp:447] Snapshotting to binary proto file /content/myCaffe/caffe_models/caffe_model_1/caffe_model_1_iter_200.caffemodel
