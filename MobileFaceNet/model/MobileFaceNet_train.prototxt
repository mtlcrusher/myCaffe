name:	"MobileFaceNet"
layer {
  name: "data"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TRAIN
  }
  transform_param {
    mirror: true
    crop_size: 112
    mean_file: "/content/data_dog_cat/mean.binaryproto"
  }

  data_param {
    source: "/content/data_dog_cat/train_lmdb"
    batch_size: 256
    backend: LMDB
  }
}

layer {
  name: "data"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TEST
  }
  transform_param {
    mirror: false
    crop_size: 112
    mean_file: "/content/data_dog_cat/mean.binaryproto"
  }

  data_param {
    source: "/content/data_dog_cat/val_lmdb"
    batch_size: 50
    backend: LMDB
  }
}

layer {
  name: "conv0"
  type: "Convolution"
  bottom: "data"
  top: "conv0"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  convolution_param {
    num_output: 64
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "msra"
    }
  }
}

layer {
	name: "conv0/bn"
	type: "BatchNorm"
	bottom: "conv0"
	top: "conv0"
	param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
    eps: 1e-5
  }
}

layer {
  name: "conv0/scale"
  type: "Scale"
  bottom: "conv0"
  top: "conv0"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}

layer {
  name: "relu0"
  type: "ReLU"
  bottom: "conv0"
  top: "conv0"
}

layer {
  name: "conv1/dw"
  type: "Convolution"
  bottom: "conv0"
  top: "conv1/dw"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  convolution_param {
    num_output: 64
    bias_term: false
    pad: 1
    kernel_size: 3
    group: 64
    weight_filler {
      type: "msra"
    }
  }
}

layer {
  name: "conv1/dw/bn"
  type: "BatchNorm"
  bottom: "conv1/dw"
  top: "conv1/dw"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
    eps: 1e-5
  }
}

layer {
  name: "conv1/dw/scale"
  type: "Scale"
  bottom: "conv1/dw"
  top: "conv1/dw"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}

layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1/dw"
  top: "conv1/dw"
}

# bottleneck

layer {
  name: "conv2/expand"
  type: "Convolution"
  bottom: "conv1/dw"
  top: "conv2/expand"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 128
    bias_term: false
    kernel_size: 1
    weight_filler {
      type: "msra"
    }
  }
}

layer {
  name: "conv2/expand/bn"
  type: "BatchNorm"
  bottom: "conv2/expand"
  top: "conv2/expand"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
    eps: 1e-5
  }
}

layer {
  name: "conv2/expand/scale"
  type: "Scale"
  bottom: "conv2/expand"
  top: "conv2/expand"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}

layer {
  name: "relu2/expand"
  type: "ReLU"
  bottom: "conv2/expand"
  top: "conv2/expand"
}

layer {
  name: "conv3/dwise"
  type: "Convolution"
  bottom: "conv2/expand"
  top: "conv3/dwise"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 1
    stride: 2
    kernel_size: 3
    group: 128
    weight_filler {
      type: "msra"
    }
    engine: CAFFE
  }
}

layer {
  name: "conv3/dwise/bn"
  type: "BatchNorm"
  bottom: "conv3/dwise"
  top: "conv3/dwise"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
    eps: 1e-5
  }
}

layer {
  name: "conv3/dwise/scale"
  type: "Scale"
  bottom: "conv3/dwise"
  top: "conv3/dwise"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}

layer {
  name: "relu3/dwise"
  type: "ReLU"
  bottom: "conv3/dwise"
  top: "conv3/dwise"
}

layer {
  name: "conv4/linear"
  type: "Convolution"
  bottom: "conv3/dwise"
  top: "conv4/linear"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 64
    bias_term: false
    kernel_size: 1
    weight_filler {
      type: "msra"
    }
  }
}

layer {
  name: "conv4/linear/bn"
  type: "BatchNorm"
  bottom: "conv4/linear"
  top: "conv4/linear"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
    eps: 1e-5
  }
}

layer {
  name: "conv4/linear/scale"
  type: "Scale"
  bottom: "conv4/linear"
  top: "conv4/linear"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}

# end of bottleneck

# bottleneck

layer {
  name: "conv5/expand"
  type: "Convolution"
  bottom: "conv4/linear"
  top: "conv5/expand"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 128
    bias_term: false
    kernel_size: 1
    weight_filler {
      type: "msra"
    }
  }
}

layer {
  name: "conv5/expand/bn"
  type: "BatchNorm"
  bottom: "conv5/expand"
  top: "conv5/expand"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
    eps: 1e-5
  }
}

layer {
  name: "conv5/expand/scale"
  type: "Scale"
  bottom: "conv5/expand"
  top: "conv5/expand"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}

layer {
  name: "relu5/expand"
  type: "ReLU"
  bottom: "conv5/expand"
  top: "conv5/expand"
}

layer {
  name: "conv6/dwise"
  type: "Convolution"
  bottom: "conv5/expand"
  top: "conv6/dwise"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 1
    kernel_size: 3
    group: 128
    weight_filler {
      type: "msra"
    }
    engine: CAFFE
  }
}

layer {
  name: "conv6/dwise/bn"
  type: "BatchNorm"
  bottom: "conv6/dwise"
  top: "conv6/dwise"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
    eps: 1e-5
  }
}

layer {
  name: "conv6/dwise/scale"
  type: "Scale"
  bottom: "conv6/dwise"
  top: "conv6/dwise"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}

layer {
  name: "relu6/dwise"
  type: "ReLU"
  bottom: "conv6/dwise"
  top: "conv6/dwise"
}

layer {
  name: "conv7/linear"
  type: "Convolution"
  bottom: "conv6/dwise"
  top: "conv7/linear"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 64
    bias_term: false
    kernel_size: 1
    weight_filler {
      type: "msra"
    }
  }
}

layer {
  name: "conv7/linear/bn"
  type: "BatchNorm"
  bottom: "conv7/linear"
  top: "conv7/linear"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
    eps: 1e-5
  }
}

layer {
  name: "conv7/linear/scale"
  type: "Scale"
  bottom: "conv7/linear"
  top: "conv7/linear"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}

# end of bottleneck

layer {
  name: "block1_1"
  type: "Eltwise"
  bottom: "conv4/linear"
  bottom: "conv7/linear"
  top: "block1_1"
}

# bottleneck

layer {
  name: "conv8/expand"
  type: "Convolution"
  bottom: "block1_1"
  top: "conv8/expand"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 128
    bias_term: false
    kernel_size: 1
    weight_filler {
      type: "msra"
    }
  }
}

layer {
  name: "conv8/expand/bn"
  type: "BatchNorm"
  bottom: "conv8/expand"
  top: "conv8/expand"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
    eps: 1e-5
  }
}

layer {
  name: "conv8/expand/scale"
  type: "Scale"
  bottom: "conv8/expand"
  top: "conv8/expand"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}

layer {
  name: "relu8/expand"
  type: "ReLU"
  bottom: "conv8/expand"
  top: "conv8/expand"
}

layer {
  name: "conv9/dwise"
  type: "Convolution"
  bottom: "conv8/expand"
  top: "conv9/dwise"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 1
    kernel_size: 3
    group: 128
    weight_filler {
      type: "msra"
    }
    engine: CAFFE
  }
}

layer {
  name: "conv9/dwise/bn"
  type: "BatchNorm"
  bottom: "conv9/dwise"
  top: "conv9/dwise"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
    eps: 1e-5
  }
}

layer {
  name: "conv9/dwise/scale"
  type: "Scale"
  bottom: "conv9/dwise"
  top: "conv9/dwise"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}

layer {
  name: "relu9/dwise"
  type: "ReLU"
  bottom: "conv9/dwise"
  top: "conv9/dwise"
}

layer {
  name: "conv10/linear"
  type: "Convolution"
  bottom: "conv9/dwise"
  top: "conv10/linear"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 64
    bias_term: false
    kernel_size: 1
    weight_filler {
      type: "msra"
    }
  }
}

layer {
  name: "conv10/linear/bn"
  type: "BatchNorm"
  bottom: "conv10/linear"
  top: "conv10/linear"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
    eps: 1e-5
  }
}

layer {
  name: "conv10/linear/scale"
  type: "Scale"
  bottom: "conv10/linear"
  top: "conv10/linear"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}

# end of bottleneck

layer {
  name: "block1_2"
  type: "Eltwise"
  bottom: "block1_1"
  bottom: "conv10/linear"
  top: "block1_2"
}

# bottleneck

layer {
  name: "conv11/expand"
  type: "Convolution"
  bottom: "block1_2"
  top: "conv11/expand"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 128
    bias_term: false
    kernel_size: 1
    weight_filler {
      type: "msra"
    }
  }
}

layer {
  name: "conv11/expand/bn"
  type: "BatchNorm"
  bottom: "conv11/expand"
  top: "conv11/expand"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
    eps: 1e-5
  }
}

layer {
  name: "conv11/expand/scale"
  type: "Scale"
  bottom: "conv11/expand"
  top: "conv11/expand"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}

layer {
  name: "relu11/expand"
  type: "ReLU"
  bottom: "conv11/expand"
  top: "conv11/expand"
}

layer {
  name: "conv12/dwise"
  type: "Convolution"
  bottom: "conv11/expand"
  top: "conv12/dwise"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 1
    kernel_size: 3
    group: 128
    weight_filler {
      type: "msra"
    }
    engine: CAFFE
  }
}

layer {
  name: "conv12/dwise/bn"
  type: "BatchNorm"
  bottom: "conv12/dwise"
  top: "conv12/dwise"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
    eps: 1e-5
  }
}

layer {
  name: "conv12/dwise/scale"
  type: "Scale"
  bottom: "conv12/dwise"
  top: "conv12/dwise"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}

layer {
  name: "relu12/dwise"
  type: "ReLU"
  bottom: "conv12/dwise"
  top: "conv12/dwise"
}

layer {
  name: "conv13/linear"
  type: "Convolution"
  bottom: "conv12/dwise"
  top: "conv13/linear"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 64
    bias_term: false
    kernel_size: 1
    weight_filler {
      type: "msra"
    }
  }
}

layer {
  name: "conv13/linear/bn"
  type: "BatchNorm"
  bottom: "conv13/linear"
  top: "conv13/linear"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
    eps: 1e-5
  }
}

layer {
  name: "conv13/linear/scale"
  type: "Scale"
  bottom: "conv13/linear"
  top: "conv13/linear"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}

# end of bottleneck

layer {
  name: "block1_3"
  type: "Eltwise"
  bottom: "block1_2"
  bottom: "conv13/linear"
  top: "block1_3"
}

# bottleneck

layer {
  name: "conv14/expand"
  type: "Convolution"
  bottom: "block1_3"
  top: "conv14/expand"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 128
    bias_term: false
    kernel_size: 1
    weight_filler {
      type: "msra"
    }
  }
}

layer {
  name: "conv14/expand/bn"
  type: "BatchNorm"
  bottom: "conv14/expand"
  top: "conv14/expand"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
    eps: 1e-5
  }
}

layer {
  name: "conv14/expand/scale"
  type: "Scale"
  bottom: "conv14/expand"
  top: "conv14/expand"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}

layer {
  name: "relu14/expand"
  type: "ReLU"
  bottom: "conv14/expand"
  top: "conv14/expand"
}

layer {
  name: "conv15/dwise"
  type: "Convolution"
  bottom: "conv14/expand"
  top: "conv15/dwise"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 1
    kernel_size: 3
    group: 128
    weight_filler {
      type: "msra"
    }
    engine: CAFFE
  }
}

layer {
  name: "conv15/dwise/bn"
  type: "BatchNorm"
  bottom: "conv15/dwise"
  top: "conv15/dwise"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
    eps: 1e-5
  }
}

layer {
  name: "conv15/dwise/scale"
  type: "Scale"
  bottom: "conv15/dwise"
  top: "conv15/dwise"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}

layer {
  name: "relu15/dwise"
  type: "ReLU"
  bottom: "conv15/dwise"
  top: "conv15/dwise"
}

layer {
  name: "conv16/linear"
  type: "Convolution"
  bottom: "conv15/dwise"
  top: "conv16/linear"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 64
    bias_term: false
    kernel_size: 1
    weight_filler {
      type: "msra"
    }
  }
}

layer {
  name: "conv16/linear/bn"
  type: "BatchNorm"
  bottom: "conv16/linear"
  top: "conv16/linear"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
    eps: 1e-5
  }
}

layer {
  name: "conv16/linear/scale"
  type: "Scale"
  bottom: "conv16/linear"
  top: "conv16/linear"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}

# end of bottleneck

layer {
  name: "block1_4"
  type: "Eltwise"
  bottom: "block1_3"
  bottom: "conv16/linear"
  top: "block1_4"
}

# bottleneck

layer {
  name: "conv17/expand"
  type: "Convolution"
  bottom: "block1_4"
  top: "conv17/expand"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 256
    bias_term: false
    kernel_size: 1
    weight_filler {
      type: "msra"
    }
  }
}

layer {
  name: "conv17/expand/bn"
  type: "BatchNorm"
  bottom: "conv17/expand"
  top: "conv17/expand"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
    eps: 1e-5
  }
}

layer {
  name: "conv17/expand/scale"
  type: "Scale"
  bottom: "conv17/expand"
  top: "conv17/expand"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}

layer {
  name: "relu17/expand"
  type: "ReLU"
  bottom: "conv17/expand"
  top: "conv17/expand"
}

layer {
  name: "conv18/dwise"
  type: "Convolution"
  bottom: "conv17/expand"
  top: "conv18/dwise"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 1
    stride: 2
    kernel_size: 3
    group: 256
    weight_filler {
      type: "msra"
    }
    engine: CAFFE
  }
}

layer {
  name: "conv18/dwise/bn"
  type: "BatchNorm"
  bottom: "conv18/dwise"
  top: "conv18/dwise"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
    eps: 1e-5
  }
}

layer {
  name: "conv18/dwise/scale"
  type: "Scale"
  bottom: "conv18/dwise"
  top: "conv18/dwise"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}

layer {
  name: "relu18/dwise"
  type: "ReLU"
  bottom: "conv18/dwise"
  top: "conv18/dwise"
}

layer {
  name: "conv19/linear"
  type: "Convolution"
  bottom: "conv18/dwise"
  top: "conv19/linear"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 128
    bias_term: false
    kernel_size: 1
    weight_filler {
      type: "msra"
    }
  }
}

layer {
  name: "conv19/linear/bn"
  type: "BatchNorm"
  bottom: "conv19/linear"
  top: "conv19/linear"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
    eps: 1e-5
  }
}

layer {
  name: "conv19/linear/scale"
  type: "Scale"
  bottom: "conv19/linear"
  top: "conv19/linear"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}

# end of bottleneck

# bottleneck

layer {
  name: "conv20/expand"
  type: "Convolution"
  bottom: "conv19/linear"
  top: "conv20/expand"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 256
    bias_term: false
    kernel_size: 1
    weight_filler {
      type: "msra"
    }
  }
}

layer {
  name: "conv20/expand/bn"
  type: "BatchNorm"
  bottom: "conv20/expand"
  top: "conv20/expand"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
    eps: 1e-5
  }
}

layer {
  name: "conv20/expand/scale"
  type: "Scale"
  bottom: "conv20/expand"
  top: "conv20/expand"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}

layer {
  name: "relu20/expand"
  type: "ReLU"
  bottom: "conv20/expand"
  top: "conv20/expand"
}

layer {
  name: "conv21/dwise"
  type: "Convolution"
  bottom: "conv20/expand"
  top: "conv21/dwise"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 1
    kernel_size: 3
    group: 256
    weight_filler {
      type: "msra"
    }
    engine: CAFFE
  }
}

layer {
  name: "conv21/dwise/bn"
  type: "BatchNorm"
  bottom: "conv21/dwise"
  top: "conv21/dwise"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
    eps: 1e-5
  }
}

layer {
  name: "conv21/dwise/scale"
  type: "Scale"
  bottom: "conv21/dwise"
  top: "conv21/dwise"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}

layer {
  name: "relu21/dwise"
  type: "ReLU"
  bottom: "conv21/dwise"
  top: "conv21/dwise"
}

layer {
  name: "conv22/linear"
  type: "Convolution"
  bottom: "conv21/dwise"
  top: "conv22/linear"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 128
    bias_term: false
    kernel_size: 1
    weight_filler {
      type: "msra"
    }
  }
}

layer {
  name: "conv22/linear/bn"
  type: "BatchNorm"
  bottom: "conv22/linear"
  top: "conv22/linear"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
    eps: 1e-5
  }
}

layer {
  name: "conv22/linear/scale"
  type: "Scale"
  bottom: "conv22/linear"
  top: "conv22/linear"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}

# end of bottleneck

# bottleneck

layer {
  name: "conv23/expand"
  type: "Convolution"
  bottom: "conv22/linear"
  top: "conv23/expand"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 256
    bias_term: false
    kernel_size: 1
    weight_filler {
      type: "msra"
    }
  }
}

layer {
  name: "conv23/expand/bn"
  type: "BatchNorm"
  bottom: "conv23/expand"
  top: "conv23/expand"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
    eps: 1e-5
  }
}

layer {
  name: "conv23/expand/scale"
  type: "Scale"
  bottom: "conv23/expand"
  top: "conv23/expand"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}

layer {
  name: "relu23/expand"
  type: "ReLU"
  bottom: "conv23/expand"
  top: "conv23/expand"
}

layer {
  name: "conv24/dwise"
  type: "Convolution"
  bottom: "conv23/expand"
  top: "conv24/dwise"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 1
    kernel_size: 3
    group: 256
    weight_filler {
      type: "msra"
    }
    engine: CAFFE
  }
}

layer {
  name: "conv24/dwise/bn"
  type: "BatchNorm"
  bottom: "conv24/dwise"
  top: "conv24/dwise"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
    eps: 1e-5
  }
}

layer {
  name: "conv24/dwise/scale"
  type: "Scale"
  bottom: "conv24/dwise"
  top: "conv24/dwise"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}

layer {
  name: "relu24/dwise"
  type: "ReLU"
  bottom: "conv24/dwise"
  top: "conv24/dwise"
}

layer {
  name: "conv25/linear"
  type: "Convolution"
  bottom: "conv24/dwise"
  top: "conv25/linear"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 128
    bias_term: false
    kernel_size: 1
    weight_filler {
      type: "msra"
    }
  }
}

layer {
  name: "conv25/linear/bn"
  type: "BatchNorm"
  bottom: "conv25/linear"
  top: "conv25/linear"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
    eps: 1e-5
  }
}

layer {
  name: "conv25/linear/scale"
  type: "Scale"
  bottom: "conv25/linear"
  top: "conv25/linear"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}

# end of bottleneck

layer {
  name: "block2_1"
  type: "Eltwise"
  bottom: "conv22/linear"
  bottom: "conv25/linear"
  top: "block2_1"
}

# bottleneck

layer {
  name: "conv26/expand"
  type: "Convolution"
  bottom: "block2_1"
  top: "conv26/expand"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 256
    bias_term: false
    kernel_size: 1
    weight_filler {
      type: "msra"
    }
  }
}

layer {
  name: "conv26/expand/bn"
  type: "BatchNorm"
  bottom: "conv26/expand"
  top: "conv26/expand"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
    eps: 1e-5
  }
}

layer {
  name: "conv26/expand/scale"
  type: "Scale"
  bottom: "conv26/expand"
  top: "conv26/expand"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}

layer {
  name: "relu26/expand"
  type: "ReLU"
  bottom: "conv26/expand"
  top: "conv26/expand"
}

layer {
  name: "conv27/dwise"
  type: "Convolution"
  bottom: "conv26/expand"
  top: "conv27/dwise"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 1
    kernel_size: 3
    group: 256
    weight_filler {
      type: "msra"
    }
    engine: CAFFE
  }
}

layer {
  name: "conv27/dwise/bn"
  type: "BatchNorm"
  bottom: "conv27/dwise"
  top: "conv27/dwise"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
    eps: 1e-5
  }
}

layer {
  name: "conv27/dwise/scale"
  type: "Scale"
  bottom: "conv27/dwise"
  top: "conv27/dwise"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}

layer {
  name: "relu21/dwise"
  type: "ReLU"
  bottom: "conv27/dwise"
  top: "conv27/dwise"
}

layer {
  name: "conv28/linear"
  type: "Convolution"
  bottom: "conv27/dwise"
  top: "conv28/linear"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 128
    bias_term: false
    kernel_size: 1
    weight_filler {
      type: "msra"
    }
  }
}

layer {
  name: "conv28/linear/bn"
  type: "BatchNorm"
  bottom: "conv28/linear"
  top: "conv28/linear"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
    eps: 1e-5
  }
}

layer {
  name: "conv28/linear/scale"
  type: "Scale"
  bottom: "conv28/linear"
  top: "conv28/linear"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}

# end of bottleneck

layer {
  name: "block2_2"
  type: "Eltwise"
  bottom: "block2_1"
  bottom: "conv28/linear"
  top: "block2_2"
}

# bottleneck

layer {
  name: "conv29/expand"
  type: "Convolution"
  bottom: "block2_2"
  top: "conv29/expand"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 256
    bias_term: false
    kernel_size: 1
    weight_filler {
      type: "msra"
    }
  }
}

layer {
  name: "conv29/expand/bn"
  type: "BatchNorm"
  bottom: "conv29/expand"
  top: "conv29/expand"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
    eps: 1e-5
  }
}

layer {
  name: "conv29/expand/scale"
  type: "Scale"
  bottom: "conv29/expand"
  top: "conv29/expand"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}

layer {
  name: "relu29/expand"
  type: "ReLU"
  bottom: "conv29/expand"
  top: "conv29/expand"
}

layer {
  name: "conv30/dwise"
  type: "Convolution"
  bottom: "conv29/expand"
  top: "conv30/dwise"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 1
    kernel_size: 3
    group: 256
    weight_filler {
      type: "msra"
    }
    engine: CAFFE
  }
}

layer {
  name: "conv30/dwise/bn"
  type: "BatchNorm"
  bottom: "conv30/dwise"
  top: "conv30/dwise"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
    eps: 1e-5
  }
}

layer {
  name: "conv30/dwise/scale"
  type: "Scale"
  bottom: "conv30/dwise"
  top: "conv30/dwise"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}

layer {
  name: "relu30/dwise"
  type: "ReLU"
  bottom: "conv30/dwise"
  top: "conv30/dwise"
}

layer {
  name: "conv31/linear"
  type: "Convolution"
  bottom: "conv30/dwise"
  top: "conv31/linear"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 128
    bias_term: false
    kernel_size: 1
    weight_filler {
      type: "msra"
    }
  }
}

layer {
  name: "conv31/linear/bn"
  type: "BatchNorm"
  bottom: "conv31/linear"
  top: "conv31/linear"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
    eps: 1e-5
  }
}

layer {
  name: "conv31/linear/scale"
  type: "Scale"
  bottom: "conv31/linear"
  top: "conv31/linear"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}

# end of bottleneck

layer {
  name: "block2_3"
  type: "Eltwise"
  bottom: "block2_2"
  bottom: "conv31/linear"
  top: "block2_3"
}

# bottleneck

layer {
  name: "conv32/expand"
  type: "Convolution"
  bottom: "block2_3"
  top: "conv32/expand"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 256
    bias_term: false
    kernel_size: 1
    weight_filler {
      type: "msra"
    }
  }
}

layer {
  name: "conv32/expand/bn"
  type: "BatchNorm"
  bottom: "conv32/expand"
  top: "conv32/expand"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
    eps: 1e-5
  }
}

layer {
  name: "conv32/expand/scale"
  type: "Scale"
  bottom: "conv32/expand"
  top: "conv32/expand"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}

layer {
  name: "relu32/expand"
  type: "ReLU"
  bottom: "conv32/expand"
  top: "conv32/expand"
}

layer {
  name: "conv33/dwise"
  type: "Convolution"
  bottom: "conv32/expand"
  top: "conv33/dwise"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 1
    kernel_size: 3
    group: 256
    weight_filler {
      type: "msra"
    }
    engine: CAFFE
  }
}

layer {
  name: "conv33/dwise/bn"
  type: "BatchNorm"
  bottom: "conv33/dwise"
  top: "conv33/dwise"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
    eps: 1e-5
  }
}

layer {
  name: "conv33/dwise/scale"
  type: "Scale"
  bottom: "conv33/dwise"
  top: "conv33/dwise"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}

layer {
  name: "relu33/dwise"
  type: "ReLU"
  bottom: "conv33/dwise"
  top: "conv33/dwise"
}

layer {
  name: "conv34/linear"
  type: "Convolution"
  bottom: "conv33/dwise"
  top: "conv34/linear"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 128
    bias_term: false
    kernel_size: 1
    weight_filler {
      type: "msra"
    }
  }
}

layer {
  name: "conv34/linear/bn"
  type: "BatchNorm"
  bottom: "conv34/linear"
  top: "conv34/linear"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
    eps: 1e-5
  }
}

layer {
  name: "conv34/linear/scale"
  type: "Scale"
  bottom: "conv34/linear"
  top: "conv34/linear"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}

# end of bottleneck

layer {
  name: "block2_4"
  type: "Eltwise"
  bottom: "block2_3"
  bottom: "conv34/linear"
  top: "block2_4"
}

# bottleneck

layer {
  name: "conv35/expand"
  type: "Convolution"
  bottom: "block2_4"
  top: "conv35/expand"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 256
    bias_term: false
    kernel_size: 1
    weight_filler {
      type: "msra"
    }
  }
}

layer {
  name: "conv35/expand/bn"
  type: "BatchNorm"
  bottom: "conv35/expand"
  top: "conv35/expand"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
    eps: 1e-5
  }
}

layer {
  name: "conv35/expand/scale"
  type: "Scale"
  bottom: "conv35/expand"
  top: "conv35/expand"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}

layer {
  name: "relu20/expand"
  type: "ReLU"
  bottom: "conv35/expand"
  top: "conv35/expand"
}

layer {
  name: "conv36/dwise"
  type: "Convolution"
  bottom: "conv35/expand"
  top: "conv36/dwise"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 1
    kernel_size: 3
    group: 256
    weight_filler {
      type: "msra"
    }
    engine: CAFFE
  }
}

layer {
  name: "conv36/dwise/bn"
  type: "BatchNorm"
  bottom: "conv36/dwise"
  top: "conv36/dwise"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
    eps: 1e-5
  }
}

layer {
  name: "conv36/dwise/scale"
  type: "Scale"
  bottom: "conv36/dwise"
  top: "conv36/dwise"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}

layer {
  name: "relu36/dwise"
  type: "ReLU"
  bottom: "conv36/dwise"
  top: "conv36/dwise"
}

layer {
  name: "conv37/linear"
  type: "Convolution"
  bottom: "conv36/dwise"
  top: "conv37/linear"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 128
    bias_term: false
    kernel_size: 1
    weight_filler {
      type: "msra"
    }
  }
}

layer {
  name: "conv37/linear/bn"
  type: "BatchNorm"
  bottom: "conv37/linear"
  top: "conv37/linear"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
    eps: 1e-5
  }
}

layer {
  name: "conv37/linear/scale"
  type: "Scale"
  bottom: "conv37/linear"
  top: "conv37/linear"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}

# end of bottleneck

layer {
  name: "block2_5"
  type: "Eltwise"
  bottom: "block2_4"
  bottom: "conv37/linear"
  top: "block2_5"
}

# bottleneck

layer {
  name: "conv38/expand"
  type: "Convolution"
  bottom: "block2_5"
  top: "conv38/expand"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 256
    bias_term: false
    kernel_size: 1
    weight_filler {
      type: "msra"
    }
  }
}

layer {
  name: "conv38/expand/bn"
  type: "BatchNorm"
  bottom: "conv38/expand"
  top: "conv38/expand"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
    eps: 1e-5
  }
}

layer {
  name: "conv38/expand/scale"
  type: "Scale"
  bottom: "conv38/expand"
  top: "conv38/expand"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}

layer {
  name: "relu38/expand"
  type: "ReLU"
  bottom: "conv38/expand"
  top: "conv38/expand"
}

layer {
  name: "conv39/dwise"
  type: "Convolution"
  bottom: "conv38/expand"
  top: "conv39/dwise"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 1
    kernel_size: 3
    group: 256
    weight_filler {
      type: "msra"
    }
    engine: CAFFE
  }
}

layer {
  name: "conv39/dwise/bn"
  type: "BatchNorm"
  bottom: "conv39/dwise"
  top: "conv39/dwise"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
    eps: 1e-5
  }
}

layer {
  name: "conv39/dwise/scale"
  type: "Scale"
  bottom: "conv39/dwise"
  top: "conv39/dwise"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}

layer {
  name: "relu39/dwise"
  type: "ReLU"
  bottom: "conv39/dwise"
  top: "conv39/dwise"
}

layer {
  name: "conv40/linear"
  type: "Convolution"
  bottom: "conv39/dwise"
  top: "conv40/linear"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 128
    bias_term: false
    kernel_size: 1
    weight_filler {
      type: "msra"
    }
  }
}

layer {
  name: "conv40/linear/bn"
  type: "BatchNorm"
  bottom: "conv40/linear"
  top: "conv40/linear"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
    eps: 1e-5
  }
}

layer {
  name: "conv40/linear/scale"
  type: "Scale"
  bottom: "conv40/linear"
  top: "conv40/linear"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}

# end of bottleneck

# bottleneck

layer {
  name: "conv41/expand"
  type: "Convolution"
  bottom: "conv40/linear"
  top: "conv41/expand"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 256
    bias_term: false
    kernel_size: 1
    weight_filler {
      type: "msra"
    }
  }
}

layer {
  name: "conv41/expand/bn"
  type: "BatchNorm"
  bottom: "conv41/expand"
  top: "conv41/expand"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
    eps: 1e-5
  }
}

layer {
  name: "conv41/expand/scale"
  type: "Scale"
  bottom: "conv41/expand"
  top: "conv41/expand"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}

layer {
  name: "relu41/expand"
  type: "ReLU"
  bottom: "conv41/expand"
  top: "conv41/expand"
}

layer {
  name: "conv42/dwise"
  type: "Convolution"
  bottom: "conv41/expand"
  top: "conv42/dwise"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 1
    kernel_size: 3
    group: 256
    weight_filler {
      type: "msra"
    }
    engine: CAFFE
  }
}

layer {
  name: "conv42/dwise/bn"
  type: "BatchNorm"
  bottom: "conv42/dwise"
  top: "conv42/dwise"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
    eps: 1e-5
  }
}

layer {
  name: "conv42/dwise/scale"
  type: "Scale"
  bottom: "conv42/dwise"
  top: "conv42/dwise"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}

layer {
  name: "relu42/dwise"
  type: "ReLU"
  bottom: "conv42/dwise"
  top: "conv42/dwise"
}

layer {
  name: "conv43/linear"
  type: "Convolution"
  bottom: "conv42/dwise"
  top: "conv43/linear"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 128
    bias_term: false
    kernel_size: 1
    weight_filler {
      type: "msra"
    }
  }
}

layer {
  name: "conv43/linear/bn"
  type: "BatchNorm"
  bottom: "conv43/linear"
  top: "conv43/linear"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
    eps: 1e-5
  }
}

layer {
  name: "conv43/linear/scale"
  type: "Scale"
  bottom: "conv43/linear"
  top: "conv43/linear"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}

# end of bottleneck

layer {
  name: "block3_1"
  type: "Eltwise"
  bottom: "conv40/linear"
  bottom: "conv43/linear"
  top: "block3_1"
}

# conv1x1

layer {
  name: "conv44"
  type: "Convolution"
  bottom: "block3_1"
  top: "conv44"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  convolution_param {
    num_output: 512
    bias_term: false
    kernel_size: 1
    weight_filler {
      type: "msra"
    }
  }
}

layer {
  name: "conv44/bn"
  type: "BatchNorm"
  bottom: "conv44"
  top: "conv44"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
    eps: 1e-5
  }
}

layer {
  name: "conv44/scale"
  type: "Scale"
  bottom: "conv44"
  top: "conv44"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}

layer {
  name: "relu44"
  type: "ReLU"
  bottom: "conv44"
  top: "conv44"
}

# end of conv1x1

# GDConv7x7

layer {
  name: "conv45"
  type: "Convolution"
  bottom: "conv44"
  top: "conv45"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  convolution_param {
    num_output: 512
    bias_term: false
    kernel_size: 7
    group: 512
    weight_filler {
      type: "msra"
    }
  }
}

layer {
  name: "conv45/bn"
  type: "BatchNorm"
  bottom: "conv45"
  top: "conv45"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
    eps: 1e-5
  }
}

layer {
  name: "conv45/scale"
  type: "Scale"
  bottom: "conv45"
  top: "conv45"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}

layer {
  name: "relu45"
  type: "ReLU"
  bottom: "conv45"
  top: "conv45"
}

# end of GDConv7x7

# linear conv1x1

layer {
  name: "conv46"
  type: "Convolution"
  bottom: "conv45"
  top: "conv46"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 2
    bias_term: true
    kernel_size: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}

layer {
  name: "accuracy"
  type: "Accuracy"
  bottom: "conv46"
  bottom: "label"
  top: "accuracy"
  include {
    phase: TEST
  }
}

layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "conv46"
  bottom: "label"
  top: "loss"
}
